# Track-Fit: ìš´ë™ ë™ì‘ í’ˆì§ˆ í‰ê°€ ì‹œìŠ¤í…œ

ProtoGCN ê¸°ë°˜ ì‹¤ì‹œê°„ ìš´ë™ ë™ì‘ ì¸ì‹ ë° í’ˆì§ˆ í‰ê°€ ì‹œìŠ¤í…œ

## ğŸ“‹ í”„ë¡œì íŠ¸ ê°œìš”

Track-Fitì€ ìš´ë™ ì˜ìƒì—ì„œ ë™ì‘ì˜ í’ˆì§ˆì„ í‰ê°€í•˜ê¸° ìœ„í•œ ë”¥ëŸ¬ë‹ ê¸°ë°˜ ì‹œìŠ¤í…œì…ë‹ˆë‹¤. [ProtoGCN](https://openaccess.thecvf.com/content/CVPR2025/html/Liu_Revealing_Key_Details_to_See_Differences_A_Novel_Prototypical_Perspective_CVPR_2025_paper.html)(Prototype Graph Convolutional Network)ì„ í™œìš©í•˜ì—¬ ìš´ë™ ë™ì‘ì˜ í”„ë¡œí† íƒ€ì…ì„ í•™ìŠµí•˜ê³ , ì‹¤ì‹œê°„ìœ¼ë¡œ ë™ì‘ì„ ì¸ì‹í•˜ë©° í’ˆì§ˆì„ í‰ê°€í•©ë‹ˆë‹¤.

- **ì‹¤ì‹œê°„ ë™ì‘ ì¸ì‹**: ì›¹ìº ì„ í†µí•œ ì‹¤ì‹œê°„ ìš´ë™ ë™ì‘ ì¸ì‹
- **5ê°€ì§€ ìš´ë™ ì§€ì›**: Barbell Biceps Curl, Bench Press, Lat Pulldown, Push-up, Tricep Pushdown
- **í”„ë¡œí† íƒ€ì… ê¸°ë°˜ í•™ìŠµ**: ProtoGCNì„ í™œìš©í•œ ìš´ë™ë³„ í”„ë¡œí† íƒ€ì… í•™ìŠµ
- **í’ˆì§ˆ í‰ê°€**: í•™ìŠµëœ í”„ë¡œí† íƒ€ì…ê³¼ì˜ ìœ ì‚¬ë„ ê¸°ë°˜ ë™ì‘ í’ˆì§ˆ í‰ê°€ 

## ğŸ—ï¸ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
track-fit/
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ exercise/              # MMCv config (ProtoGCNìš©)
â”‚   â”‚   â”œâ”€â”€ j.py              # Full fine-tuning config
â”‚   â”‚   â””â”€â”€ j_freeze.py       # Freeze backbone config
â”‚   â””â”€â”€ hydra/                # Hydra experiment configs
â”‚       â”œâ”€â”€ config.yaml       # Main config
â”‚       â”œâ”€â”€ experiment/       # Experiment presets
â”‚       â”‚   â”œâ”€â”€ phase1_freeze.yaml
â”‚       â”‚   â”œâ”€â”€ phase2_finetune.yaml
â”‚       â”‚   â””â”€â”€ debug.yaml
â”‚       â”œâ”€â”€ model/
â”‚       â”‚   â””â”€â”€ protogcn.yaml
â”‚       â””â”€â”€ training/
â”‚           â””â”€â”€ default.yaml
â”œâ”€â”€ demo/                      # Real-time demo app
â”‚   â”œâ”€â”€ app/                  # Web application
â”‚   â”œâ”€â”€ extractor/            # MediaPipe keypoint extraction server
â”‚   â””â”€â”€ inferencer/           # ProtoGCN inference server
â”œâ”€â”€ external/
â”‚   â””â”€â”€ ProtoGCN/             # ProtoGCN submodule
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ create_dataset.py     # Dataset creation
â”‚   â”œâ”€â”€ extract_keypoint_mediapipe.py  # Keypoint extraction
â”‚   â””â”€â”€ visualize_keypoints_mediapipe.py  # Visualization
â”œâ”€â”€ freeze_backbone_hook.py    # Custom training hook
â””â”€â”€ train_hydra.py            # Hydra training script
```

## ğŸš€ ì„¤ì¹˜ ë° í™˜ê²½ ì„¤ì •

### 1. ì €ì¥ì†Œ í´ë¡  ë° ì„œë¸Œëª¨ë“ˆ ì´ˆê¸°í™”

```bash
git clone https://github.com/jihyun-0611/track-fit.git
cd track-fit

# ProtoGCN ì„œë¸Œëª¨ë“ˆ ì´ˆê¸°í™”
git submodule update --init --recursive

# ProtoGCN í™˜ê²½ ì„¤ì •
cd external/ProtoGCN
conda env create -f protogcn.yaml
conda activate protogcn
pip install -e .

# Hydra ì„¤ì¹˜ (ì‹¤í—˜ ê´€ë¦¬ìš©)
cd ../..
pip install hydra-core omegaconf

pip install python-dotenv
```

```bash
# MediaPipe í™˜ê²½ (í‚¤í¬ì¸íŠ¸ ì¶”ì¶œ ë° ì›¹ ì„œë²„ìš©)
conda create -n mediapipe python=3.8
conda activate mediapipe
pip install -r demo/extractor/requirements.txt
```

### 2. í™˜ê²½ ë³€ìˆ˜ ì„¤ì •

`.env` íŒŒì¼ ìƒì„±:
```bash
BASE_DIR=/path/to/track-fit
DATA_DIR=/path/to/track-fit/data
CHECKPOINT_DIR=/path/to/track-fit/checkpoints
WORK_DIR=/path/to/track-fit/work_dirs
PRETRAINED=/path/to/track-fit/checkpoints/finegym_j/best.pth
DATASET_PATH=/path/to/track-fit/data/exercise_dataset.pkl
```

## ğŸ“Š ë°ì´í„° ì¤€ë¹„

https://www.kaggle.com/datasets/hasyimabdillah/workoutfitness-video

### 1. ë¹„ë””ì˜¤ ë°ì´í„° êµ¬ì¡°

```
data/
â”œâ”€â”€ sample_videos/
â”‚   â”œâ”€â”€ barbell biceps curl/
â”‚   â”œâ”€â”€ bench press/
â”‚   â”œâ”€â”€ lat pulldown/
â”‚   â”œâ”€â”€ push-up/
â”‚   â””â”€â”€ tricep Pushdown/
â””â”€â”€ filter_meta.csv  # ë¹„ë””ì˜¤ ë©”íƒ€ë°ì´í„°
```

### 2. í‚¤í¬ì¸íŠ¸ ì¶”ì¶œ

```bash
conda activate mediapipe

# ê¸°ë³¸ ì‹¤í–‰ (.envì˜ DATA_DIR)
python scripts/extract_keypoint_mediapipe.py

# ì»¤ìŠ¤í…€ data directory
python scripts/extract_keypoint_mediapipe.py --data-dir /path/to/data

# ì‹ ë¢°ë„ ì„ê³„ê°’ ì¡°ì •
python scripts/extract_keypoint_mediapipe.py --min-detection-confidence 0.7 --min-tracking-confidence 0.7
```

### 3. ë°ì´í„°ì…‹ ìƒì„±

```bash
# ê¸°ë³¸ ì‹¤í–‰ (.envì˜ DATA_DIR ì‚¬ìš© ë˜ëŠ” ìë™ íƒìƒ‰)
python scripts/create_dataset.py

# ì»¤ìŠ¤í…€ data directory
python scripts/create_dataset.py --data-dir /path/to/data

# Train/validation split ë¹„ìœ¨ ë³€ê²½
python scripts/create_dataset.py --train-ratio 0.9 --random-seed 123
```

### 4. í‚¤í¬ì¸íŠ¸ ì‹œê°í™”

```bash
# íŠ¹ì • ë¹„ë””ì˜¤ì˜ í‚¤í¬ì¸íŠ¸ ì‹œê°í™”
python scripts/visualize_keypoints_mediapipe.py \
    --video-name "bench press_57" \
    --exercise-type "bench press"

# ì €ì¥ë§Œ í•˜ê³  í™”ë©´ì— í‘œì‹œí•˜ì§€ ì•Šê¸°
python scripts/visualize_keypoints_mediapipe.py \
    --video-name "bench press_57" \
    --exercise-type "bench press" \
    --no-show
```

## ğŸ‹ï¸ ëª¨ë¸ í•™ìŠµ

### ì‚¬ì „í•™ìŠµ ëª¨ë¸ ì¤€ë¹„

FineGYM ë°ì´í„°ì…‹ìœ¼ë¡œ ì‚¬ì „í•™ìŠµëœ ëª¨ë¸ì„ [ì—¬ê¸°ì„œ](https://github.com/firework8/ProtoGCN/blob/ddf7f274f9f5d9e45a2fcfeb299bfb3fd7c2303d/data/README.md) ë‹¤ìš´ë¡œë“œ:
```bash
mkdir -p checkpoints/finegym_j
# best_top1_acc_epoch_141.pth íŒŒì¼ì„ checkpoints/finegym_j/ì— ë°°ì¹˜
```

### í•™ìŠµ ì‹¤í–‰

ProtoGCN í™˜ê²½ í™œì„±í™” í•„ìš”
```bash
conda activate protogcn
```

#### í•™ìŠµ ì„¤ì • 

**Phase 1** (`phase1_freeze.yaml`):
- 20 epochs
- Headë§Œ í•™ìŠµ (backbone freeze)
- Learning rate: 0.01
- Optimizer: SGD with Nesterov momentum
- LR Schedule: CosineAnnealing

**Phase 2** (`phase2_finetune.yaml`):
- 80 epochs
- ì „ì²´ íŒŒì¸íŠœë‹
- Learning rate: 0.001
- Optimizer: SGD with Nesterov momentum
- LR Schedule: CosineAnnealing

#### í•™ìŠµ ì‹¤í–‰

```bash
# Phase 1: Backbone freeze, Headë§Œ í•™ìŠµ (20 epochs)
python train_hydra.py experiment=phase1_freeze

# Phase 2: ì „ì²´ íŒŒì¸íŠœë‹ (80 epochs)
python train_hydra.py experiment=phase2_finetune

# ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ (2 epochs)
python train_hydra.py experiment=debug
```

#### ì„¤ì • ì»¤ìŠ¤í„°ë§ˆì´ì§•

**í•˜ì´í¼íŒŒë¼ë¯¸í„°**:
```bash
# Learning rate ë³€ê²½
python train_hydra.py experiment=phase1_freeze training.optimizer.lr=0.02

# Epoch ìˆ˜ ë³€ê²½
python train_hydra.py experiment=phase2_finetune training.epochs=100

# Batch size ë³€ê²½
python train_hydra.py training.batch_size=8

# ì—¬ëŸ¬ ì„¤ì • ë™ì‹œ ë³€ê²½
python train_hydra.py experiment=phase1_freeze \
    training.epochs=30 \
    training.optimizer.lr=0.02 \
    training.batch_size=8 \
    model.num_prototype=100
```

**Pretrained ëª¨ë¸ ì§€ì •**:
```bash
# Phase 2ì—ì„œ Phase 1 ê²°ê³¼ ì‚¬ìš©
python train_hydra.py experiment=phase2_finetune \
    pretrained=work_dirs/exercise/j_freeze/best_top1_acc_epoch_13.pth
```

**GPU ì„¤ì •**:
```bash
python train_hydra.py training.gpus=2
```

#### í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„œì¹˜ (Multirun)

ì—¬ëŸ¬ ì„¤ì •ì„ ìë™ìœ¼ë¡œ ì‹¤í—˜:
```bash
# ì—¬ëŸ¬ learning rate í…ŒìŠ¤íŠ¸
python train_hydra.py -m training.optimizer.lr=0.001,0.01,0.05

# ì—¬ëŸ¬ ì¡°í•© í…ŒìŠ¤íŠ¸ (2Ã—2=4ê°œ ì‹¤í—˜ ìë™ ì‹¤í–‰)
python train_hydra.py -m \
    training.optimizer.lr=0.001,0.01 \
    training.batch_size=4,8
```

#### ì»¤ìŠ¤í…€ ì‹¤í—˜

`configs/hydra/experiment/my_experiment.yaml` ìƒì„±:
```yaml
# @package _global_

mmcv_config: configs/exercise/j.py

training:
  epochs: 50
  optimizer:
    lr: 0.005

experiment:
  name: my_experiment
  work_dir: ${project.work_dir}/my_experiment

pretrained: ${project.checkpoint_dir}/finegym_j/best_top1_acc_epoch_141.pth
```

ì‹¤í–‰:
```bash
python train_hydra.py experiment=my_experiment
```




## ğŸ® ë°ëª¨ ì‹¤í–‰

### ë°ëª¨ ì„œë²„ ì‹œì‘

```bash
cd demo/scripts
bash run_demo.sh
```

ë˜ëŠ” ê° ì„œë²„ë¥¼ ê°œë³„ì ìœ¼ë¡œ ì‹¤í–‰:

```bash
# Terminal 1: MediaPipe í‚¤í¬ì¸íŠ¸ ì¶”ì¶œ ì„œë²„
conda activate mediapipe
cd demo/extractor
python api.py  # http://localhost:8001

# Terminal 2: ProtoGCN ì¶”ë¡  ì„œë²„
conda activate protogcn
cd demo/inferencer
python api.py  # http://localhost:8002

# Terminal 3: ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜
conda activate mediapipe
cd demo/app
python main.py  # http://localhost:8000
```


## ğŸ”¬ ë™ì‘ í’ˆì§ˆ í‰ê°€

í•™ìŠµëœ í”„ë¡œí† íƒ€ì…ê³¼ ì…ë ¥ ë™ì‘ì˜ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•˜ì—¬ í’ˆì§ˆì„ í‰ê°€í•©ë‹ˆë‹¤.

### 1. L2 Normalized Cosine Similarity
- ë²”ìœ„: [-1, 1], 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ìœ ì‚¬
- Temperature scaling ì ìš© ê°€ëŠ¥

### 2. ê´€ì ˆë³„ Reconstruction Error
- ì›ë³¸ vs ë³µì›ëœ graphì˜ ê´€ì ˆë³„ ì°¨ì´ ê³„ì‚°
- ì˜ëª»ëœ ìì„¸ì˜ êµ¬ì²´ì  ìœ„ì¹˜ íŒŒì•… ê°€ëŠ¥

## ğŸ“ˆ ì„±ëŠ¥

### í•™ìŠµ ê²°ê³¼
- 5ê°œ ìš´ë™ í´ë˜ìŠ¤ ë¶„ë¥˜
- 227ê°œ ë¹„ë””ì˜¤ (181 train, 46 val)
- Best validation accuracy: 0.9565% (epoch 15)

### ì‹¤ì‹œê°„ ì¶”ë¡ 
- 60 í”„ë ˆì„ ë²„í¼ë§ í›„ ì‹¤ì‹œê°„ ì˜ˆì¸¡
- ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ë°©ì‹ìœ¼ë¡œ ì§€ì†ì  ì—…ë°ì´íŠ¸
- 300 í”„ë ˆì„ ë„ë‹¬ ì‹œ ìë™ ë¦¬ì…‹

## ğŸ› ï¸ ê¸°ìˆ  ìŠ¤íƒ

- **Deep Learning Framework**: PyTorch 2.6.0
- **Experiment Management**: Hydra + OmegaConf
- **Pose Estimation**: MediaPipe
- **GCN Model**: ProtoGCN (ì„œë¸Œëª¨ë“ˆ)
- **Web Framework**: FastAPI
- **Frontend**: WebSocket + Canvas API
- **Computer Vision**: OpenCV

## ğŸ“š ì°¸ê³  ë¬¸í—Œ

- ProtoGCN: [GitHub Repository](https://github.com/firework8/ProtoGCN.git)
- MediaPipe Pose: [Google MediaPipe](https://google.github.io/mediapipe/solutions/pose)

## ğŸ“„ ë¼ì´ì„ ìŠ¤

This project is for research purposes only.


---

**Note**: ì´ í”„ë¡œì íŠ¸ëŠ” í˜„ì¬ ê°œë°œ ì¤‘ì´ë©°, ë™ì‘ í’ˆì§ˆ í‰ê°€ ê¸°ëŠ¥ì€ ì¶”í›„ ì¶”ê°€ êµ¬í˜„ ì˜ˆì •ì…ë‹ˆë‹¤.